{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWa0wU6JCklh",
        "outputId": "da14a951-0055-43da-f0e3-66e50fa26c0e"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install --upgrade google-cloud\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is-m_9HuCklj"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-bigquery\n",
        "\n",
        "!gcloud --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IytcDhvDCklj",
        "outputId": "ab302329-eb21-4d46-bdef-150ef432027d"
      },
      "outputs": [],
      "source": [
        "!gcloud auth list\n",
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlseQdGOCklj"
      },
      "outputs": [],
      "source": [
        "project_name = \"data-project-455021\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "w21VBkFQCklj",
        "outputId": "f07365fb-884f-4c46-c17f-76675b84ee6b"
      },
      "outputs": [],
      "source": [
        "#Run to test that everythings working with google cloud\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import db_dtypes as db_dtypes\n",
        "\n",
        "client = bigquery.Client(project=project_name)\n",
        "\n",
        "# List datasets in the specified project\n",
        "datasets = list(client.list_datasets())\n",
        "\n",
        "# Print the dataset names\n",
        "for dataset in datasets:\n",
        "    print(dataset.dataset_id)from collections import Counter\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "    top_n = 10\n",
        "    label_counts = Counter(y)\n",
        "\n",
        "\n",
        "sql = f'SELECT * FROM `{project_name}.mimic3_v1_4.PATIENTS`'\n",
        "query_job = client.query(sql)\n",
        "\n",
        "# df = query_job.to_dataframe()\n",
        "rows = query_job.result()\n",
        "patients_df = pd.DataFrame([dict(row) for row in rows])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "patients_df['GENDER'].value_counts().plot(kind='bar')\n",
        "\n",
        "plt.title('Gender Distribution in MIMIC-III Patient Dataset')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h1eDowhCklm",
        "outputId": "6b3a10f7-38cc-4363-a730-3e4db4400d02"
      },
      "outputs": [],
      "source": [
        "# SQL query to join the admissions table with the diagnoses table\n",
        "sql = f\"\"\"\n",
        "SELECT\n",
        "    a.SUBJECT_ID,\n",
        "    a.HADM_ID,\n",
        "    d.ICD9_CODE,\n",
        "    a.ADMITTIME\n",
        "FROM\n",
        "    `{project_name}.mimic3_v1_4.ADMISSIONS` as a\n",
        "LEFT JOIN\n",
        "    `{project_name}.mimic3_v1_4.DIAGNOSES_ICD` as d\n",
        "ON\n",
        "    a.SUBJECT_ID = d.SUBJECT_ID AND a.HADM_ID = d.HADM_ID\n",
        "\"\"\"\n",
        "query_job = client.query(sql)\n",
        "rows = query_job.result()\n",
        "\n",
        "diagnoses_df = pd.DataFrame([dict(row) for row in rows])\n",
        "\n",
        "diagnoses_df['DIAGNOSIS_FLAG'] = diagnoses_df['ICD9_CODE'].notnull()\n",
        "\n",
        "# Left join because want to keep all admissions to the hospital, and add false to flag if no diagnosis was given\n",
        "\n",
        "ground_truth_df = diagnoses_df[['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'ICD9_CODE', 'DIAGNOSIS_FLAG']]\n",
        "\n",
        "ground_truth_df['DIAGNOSIS_FLAG'].fillna(False, inplace=True)\n",
        "print(\"Ground Truth DataFrame:\", len(ground_truth_df))\n",
        "print(ground_truth_df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLISpAENCklm",
        "outputId": "bbe79961-a056-43df-a9d8-a85f66d90580"
      },
      "outputs": [],
      "source": [
        "# Count the occurrences of each ICD9_CODE\n",
        "icd9_counts = diagnoses_df['ICD9_CODE'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "icd9_counts.head(20).plot(kind='bar')\n",
        "\n",
        "plt.title('Top 20 Most Common ICD-9 Diagnoses')\n",
        "plt.xlabel('ICD-9 Code')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1JFvlT5Ckln",
        "outputId": "ae69e444-bf09-41e6-9dd8-504ee03e54ea"
      },
      "outputs": [],
      "source": [
        "icd_d_sql = f'SELECT * FROM `{project_name}.mimic3_v1_4.D_ICD_DIAGNOSES`'\n",
        "icd_df_job = client.query(icd_d_sql)\n",
        "icd_df_rows = icd_df_job.result()\n",
        "icd_df = pd.DataFrame([dict(row) for row in icd_df_rows])\n",
        "icd_df = icd_df.dropna(how='all')\n",
        "\n",
        "ground_truth_df = pd.merge(diagnoses_df, icd_df, on=['ICD9_CODE'], how='left')\n",
        "print(ground_truth_df.head(5))\n",
        "\n",
        "icd9_counts = ground_truth_df['SHORT_TITLE'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "icd9_counts.head(20).plot(kind='bar')\n",
        "\n",
        "plt.title('Top 20 Most Common ICD-9 Diagnoses')\n",
        "plt.xlabel('ICD-9 Code')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHHsYsYlCklo"
      },
      "outputs": [],
      "source": [
        "\n",
        "patients_df = patients_df.dropna(how='all')\n",
        "admissions_sql = f'SELECT * FROM `{project_name}.mimic3_v1_4.ADMISSIONS`'\n",
        "admissions_query_job = client.query(admissions_sql)\n",
        "admissions_rows = admissions_query_job.result()\n",
        "admissions_df = pd.DataFrame([dict(row) for row in admissions_rows])\n",
        "admissions_df = admissions_df.dropna(how='all')\n",
        "print(admissions_df['SUBJECT_ID'].isin(patients_df['SUBJECT_ID']).all())  # True means filtering is unnecessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOvC7TT0Ckls",
        "outputId": "75b8698e-1858-4a32-d716-9e3b064af3a2"
      },
      "outputs": [],
      "source": [
        "note_events_sql = f\"\"\"\n",
        "SELECT SUBJECT_ID, HADM_ID, DESCRIPTION, ISERROR, TEXT, CHARTDATE\n",
        "FROM (\n",
        "  SELECT *, ROW_NUMBER() OVER (PARTITION BY SUBJECT_ID ORDER BY CHARTDATE DESC) AS rn\n",
        "  FROM `{project_name}.mimic3_v1_4.NOTEEVENTS`\n",
        "  WHERE HADM_ID IS NOT NULL\n",
        ")\n",
        "WHERE rn = 1\n",
        "\"\"\"\n",
        "\n",
        "note_job = client.query(note_events_sql)\n",
        "note_rows = note_job.result()\n",
        "note_df = pd.DataFrame([dict(row) for row in note_rows])\n",
        "note_df = note_df.dropna(how='all')\n",
        "print(note_df.head(5))\n",
        "print(len(note_df))\n",
        "# print(note_df['TEXT'].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxuJf7iACklt",
        "outputId": "321fe8c0-fad3-4b04-9b16-9eddb8e11d87"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "filename = 'new_patient_notes.csv'\n",
        "header = ['patient_id', 'notes']\n",
        "rows = note_df[['SUBJECT_ID', 'TEXT']].values.tolist()\n",
        "\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    csvwriter.writerow(header)\n",
        "    csvwriter.writerows(rows)\n",
        "\n",
        "print(f\"Created CSV file: {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zxym9fpECklt",
        "outputId": "eb448c0c-8204-4f78-a81a-bd61d97ea448"
      },
      "outputs": [],
      "source": [
        "print(\"Number of entries in CSV file\", len(rows))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgvahbAECklu"
      },
      "outputs": [],
      "source": [
        "diag_sql = f\"\"\"\n",
        "SELECT SUBJECT_ID, HADM_ID, ICD9_CODE AS PRIMARY_DIAGNOSIS\n",
        "FROM {project_name}.mimic3_v1_4.DIAGNOSES_ICD\n",
        "WHERE SEQ_NUM = 1\n",
        "\"\"\"\n",
        "diag_job = client.query(diag_sql)\n",
        "diag_rows = diag_job.result()\n",
        "diag_df = pd.DataFrame([dict(row) for row in diag_rows])\n",
        "combined_df = pd.merge(note_df, diag_df, on=['SUBJECT_ID', 'HADM_ID'], how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDUQYJI8rYZJ",
        "outputId": "f8adb9a3-5698-4c27-f2ad-5fbcf70fd55e"
      },
      "outputs": [],
      "source": [
        "num_unique_diagnoses = combined_df['PRIMARY_DIAGNOSIS'].nunique()\n",
        "print(f\"Number of unique ICD-9 diagnosis: {num_unique_diagnoses}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqZM8TYjCklu"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "combined_df['diagnosis_label'] = label_encoder.fit_transform(combined_df['PRIMARY_DIAGNOSIS'])\n",
        "y_labels = combined_df['diagnosis_label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r1AUgHyCklu"
      },
      "outputs": [],
      "source": [
        "x1 = pd.read_csv('compiled_important_notes.csv')\n",
        "\n",
        "x1['diagnosis_label'] = y_labels\n",
        "x1 = x1.dropna(subset=['important_notes', 'diagnosis_label'])\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "\n",
        "X = vectorizer.fit_transform(x1['important_notes'])\n",
        "y = x1['diagnosis_label']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdbdJcg4Cklv"
      },
      "outputs": [],
      "source": [
        "# (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw5hNBXICklv",
        "outputId": "043d077b-fa2f-439b-b9e5-9f6cc667c3f1"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "lg_acc = model.score(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iRBD8fTCklv"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    class_weight='balanced',\n",
        "    n_estimators=200,\n",
        "    max_depth=30,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiSDYpNvCklw",
        "outputId": "e553f350-4006-4f7a-fb5f-eca6b9f460dd"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
        "rf_accuracy =  accuracy_score(y_train, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "lCXDyYhvH69S",
        "outputId": "41fd4b8a-6a7e-4cb1-c1b5-8aaa1cbe52e4"
      },
      "outputs": [],
      "source": [
        "models = ['Logistic Regression', 'Random Forest']\n",
        "accuracies = [lg_acc, rf_accuracy]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "bars = plt.bar(models, accuracies)\n",
        "\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut7OsxKCCxZW",
        "outputId": "d68c8ed3-17b5-4b46-8162-b25b9b970c87"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv('new_patient_notes.csv')\n",
        "\n",
        "new_df = combined_df\n",
        "print(combined_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5srwFBMmDVZ9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.optim import AdamW\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9THSFCARDQls",
        "outputId": "cb37ffb9-1bbc-418d-ba19-ee4f02911a72"
      },
      "outputs": [],
      "source": [
        "df = new_df.copy()\n",
        "df = df.dropna(subset=['TEXT', 'PRIMARY_DIAGNOSIS'])\n",
        "\n",
        "top_n = 10\n",
        "top_labels = df['PRIMARY_DIAGNOSIS'].value_counts().nlargest(top_n).index\n",
        "df = df[df['PRIMARY_DIAGNOSIS'].isin(top_labels)]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['PRIMARY_DIAGNOSIS'])\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "class MIMICDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df['TEXT'].tolist(), df['label'].tolist(),\n",
        "    test_size=0.2, stratify=df['label'], random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = MIMICDataset(X_train, y_train, tokenizer)\n",
        "val_dataset = MIMICDataset(X_val, y_val, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    num_labels=len(top_labels)\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
        "\n",
        "    for step, batch in loop:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            loop.set_description(f\"Epoch {epoch+1}\")\n",
        "            loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1} average loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "        logits = model(**inputs).logits\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        labels = batch['labels'].numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
        "print(\"F1 Score:\", f1_score(all_labels, all_preds, average='weighted'))\n",
        "print(\"Classification Report:\\n\", classification_report(all_labels, all_preds, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6BSdSLwjhqt"
      },
      "outputs": [],
      "source": [
        "bert_acc = accuracy_score(all_labels, all_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "7yCzXQkajmh-",
        "outputId": "d7b2c49a-aeb5-465d-f34d-4d46a08103ea"
      },
      "outputs": [],
      "source": [
        "models = ['Logistic Regression', 'Random Forest', 'BERT Model']\n",
        "accuracies = [lg_acc, rf_accuracy, bert_acc]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "bars = plt.bar(models, accuracies)\n",
        "\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CD_4EteXpth9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "#basic data cleaning of notes\n",
        "\n",
        "def clean_notes(text):\n",
        "    text = str(text).lower()\n",
        "\n",
        "    text = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', '', text)\n",
        "\n",
        "    text = re.sub(r'\\d{1,4}[-/]\\d{1,2}[-/]\\d{1,4}', ' ', text)\n",
        "    text = re.sub(r'\\d{1,2}:\\d{2}(?: ?[ap]m)?', ' ', text)\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "\n",
        "    text = re.sub(r'\\b(?:chief complaint|hpi|assessment and plan|ros|history|allergies|labs|radiology|ecg|plan|exam|vitals|disposition|medications|home meds|past medical history|review of systems|comments|communication):', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "\n",
        "    tokens = text.split()\n",
        "    tokens = [token for token in tokens if token not in ENGLISH_STOP_WORDS and len(token) > 2 and token.isalpha()]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "clean_x['cleaned_notes'] = clean_x['notes'].apply(clean_notes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBThOx9DqV2R",
        "outputId": "4151590a-df4a-4981-e540-d0a3a85b08d5"
      },
      "outputs": [],
      "source": [
        "print(clean_x.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r-CaQiZZleS",
        "outputId": "c4a5ea0c-93fc-41fb-d586-5c08515af3cf"
      },
      "outputs": [],
      "source": [
        "top_n = 10\n",
        "label_counts = Counter(y)\n",
        "top_labels = [label for label, _ in label_counts.most_common(top_n)]\n",
        "mask = [label in top_labels for label in y]\n",
        "\n",
        "X_filtered = embeddings[mask]\n",
        "y_filtered = np.array(y)[mask]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_filtered_encoded = label_encoder.fit_transform(y_filtered)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_filtered, y_filtered_encoded, test_size=0.2, random_state=42, stratify=y_filtered_encoded\n",
        ")\n",
        "\n",
        "clf = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced',\n",
        "    solver='lbfgs',\n",
        "    n_jobs=-1\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "new_lg_acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", classification_report(\n",
        "    y_test, y_pred, target_names=label_encoder.classes_.astype(str)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouhLw94ZriVh"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "important_notes = pd.read_csv(\"compiled_important_notes.csv\")\n",
        "\n",
        "combined_df = pd.merge(diag_df, important_notes, left_on='SUBJECT_ID', right_on='patient_id', how='inner')\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_embeddings_batched(texts, batch_size=16):\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size)):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        tokens = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**tokens)\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "texts = combined_df['important_notes'].fillna('').astype(str).tolist()\n",
        "embeddings = get_embeddings_batched(texts, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "YvMCZM4MoWXe",
        "outputId": "d2b13232-2be8-445d-fb4c-2040ea960699"
      },
      "outputs": [],
      "source": [
        "models = ['Logistic Regression', 'Random Forest']\n",
        "accuracies = [lg_acc, rf_accuracy]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "bars = plt.bar(models, accuracies)\n",
        "\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('TF-IDF Basic Model Accuracy Comparison')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "iNXISRl2oe5x",
        "outputId": "270655b9-cc50-4026-87b0-ae86a93f845d"
      },
      "outputs": [],
      "source": [
        "models = ['Logistic Regression', 'BERT Model']\n",
        "accuracies = [new_lg_acc, bert_acc]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "bars = plt.bar(models, accuracies)\n",
        "\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Comparison (Top 10)')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
