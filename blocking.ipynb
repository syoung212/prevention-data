{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import time\n",
    "import requests\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = pd.read_csv('comprehensive_medical_notes.csv')  \n",
    "y1 = pd.read_csv('new_ground_truth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pairs(pred_pairs, ground_truth_clusters):\n",
    "    true_pairs = set()\n",
    "    for cluster in ground_truth_clusters:\n",
    "        for a in range(len(cluster)):\n",
    "            for b in range(a+1, len(cluster)):\n",
    "                i,j = cluster[a], cluster[b]\n",
    "                true_pairs.add((min(i,j), max(i,j)))\n",
    "\n",
    "    all_pairs = pred_pairs.union(true_pairs)\n",
    "    y_true = [1 if p in true_pairs else 0 for p in all_pairs]\n",
    "    y_pred = [1 if p in pred_pairs  else 0 for p in all_pairs]\n",
    "\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred,\n",
    "        average='binary',\n",
    "        zero_division=0\n",
    "    )\n",
    "    return {'precision': p, 'recall': r, 'f_score': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityResolutionPipeline:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.cleaned_data = None\n",
    "        self.blocks = defaultdict(list)\n",
    "        self.candidate_pairs = set()\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.cleaned_data = data.copy()\n",
    "        self.cleaned_data['cleaned_title'] = self.cleaned_data['important_notes'].apply(str)\n",
    "        return self.data\n",
    "    \n",
    "    def clean_data(self):\n",
    "        self.cleaned_data = self.data.copy()\n",
    "        self.cleaned_data['cleaned_title'] = self.cleaned_data['important_notes']\n",
    "        return self.cleaned_data\n",
    "    \n",
    "    def create_blocks(self):    \n",
    "        self.blocks = defaultdict(list)\n",
    "        \n",
    "        for idx, row in self.cleaned_data.iterrows():\n",
    "            tokens = row['cleaned_title'].split()\n",
    "            for token in tokens:\n",
    "                if len(token) > 2:  \n",
    "                    self.blocks[token].append(row['patient_id'])\n",
    "        \n",
    "        return self.blocks\n",
    "\n",
    "    \n",
    "    def filter_blocks(self, tau):\n",
    "        # max_blocks=5000\n",
    "        filtered_blocks = {\n",
    "            token: records\n",
    "            for token, records in self.blocks.items()\n",
    "            if 1 < len(records) < tau\n",
    "        }\n",
    "\n",
    "        # if max_blocks and len(filtered_blocks) > max_blocks:\n",
    "        #     tokens_sorted = sorted(\n",
    "        #         filtered_blocks.keys(),\n",
    "        #         key=lambda t: len(filtered_blocks[t]),\n",
    "        #         reverse=True,\n",
    "        #     )\n",
    "        #     keep = set(tokens_sorted[:max_blocks])\n",
    "        #     filtered_blocks = {t: filtered_blocks[t] for t in keep}\n",
    "\n",
    "        self.filtered_blocks = filtered_blocks\n",
    "\n",
    "        return filtered_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x1\n",
    "pipeline = EntityResolutionPipeline()\n",
    "pipeline.set_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_blocks_global = []\n",
    "def run_pipeline(tau, alpha, clean_the_data =True):  \n",
    "    blocks = defaultdict(list)\n",
    "    candidate_pairs = set()\n",
    "    matches = set()\n",
    "    clusters = []\n",
    "    tau = 50\n",
    "    alpha = 0.7\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pipeline = EntityResolutionPipeline()\n",
    "    data = pd.read_csv('compiled_important_notes.csv')\n",
    "    pipeline.set_data(data)\n",
    "    ground_truth = pd.read_csv('new_primary_diagnosis.csv').values.tolist()\n",
    "        \n",
    "    if clean_the_data:\n",
    "        data = pipeline.clean_data()\n",
    "\n",
    "    # Blocking\n",
    "    blocking_start = time.time()\n",
    "    blocks = pipeline.create_blocks()\n",
    "    filtered_blocks, candidates = pipeline.filter_blocks(tau)\n",
    "    filtered_blocks_global = filtered_blocks\n",
    "    blocking_time = time.time() - blocking_start\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'blocking': {\n",
    "            'time': blocking_time,\n",
    "        },\n",
    "        'total_time': blocking_time, \n",
    "        'filtered_blocks_global': filtered_blocks_global\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = run_pipeline(50, 0.7, False)\n",
    "\n",
    "df = pd.read_csv('comprehensive_medical_notes.csv')\n",
    "block_rows = []\n",
    "filtered_blocks_global = best_results['filtered_blocks_global']\n",
    "\n",
    "\n",
    "for token, patient_ids in filtered_blocks_global.items():\n",
    "    matches = df[df['patient_id'].isin(patient_ids)]\n",
    "\n",
    "    agg_dict = (\n",
    "        matches\n",
    "        .groupby('patient_id')['important_notes']\n",
    "        .apply(lambda notes: ' '.join(notes.head(5)))\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    block_list_str = ','.join(map(str, patient_ids))\n",
    "    all_notes_list = [agg_dict[pid] for pid in patient_ids if pid in agg_dict]\n",
    "    all_notes_str = ' '.join(all_notes_list)\n",
    "\n",
    "    block_rows.append({\n",
    "        'block_list_str': block_list_str,\n",
    "        'all_notes': all_notes_str\n",
    "    })\n",
    "\n",
    "result_df = pd.DataFrame(block_rows)\n",
    "result_df.to_csv('filtered_blocks_notes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_patients = pd.read_csv('compiled_important_notes.csv')['patient_id'].astype(int)\n",
    "\n",
    "test_ids = all_patients.sample(frac=0.03, random_state=50).tolist()\n",
    "\n",
    "blocks_df = pd.read_csv('filtered_blocks_notes.csv')\n",
    "blocks_df['patient_list'] = blocks_df['block_list_str'].str.split(',')\n",
    "\n",
    "exploded = (\n",
    "    blocks_df\n",
    "    .explode('patient_list')\n",
    "    .rename(columns={'patient_list': 'patient_id'})\n",
    ")\n",
    "exploded['patient_id'] = exploded['patient_id'].astype(int)\n",
    "\n",
    "test_set = exploded[exploded['patient_id'].isin(test_ids)][\n",
    "    ['patient_id', 'block_list_str', 'all_notes']\n",
    "].drop_duplicates('patient_id').reset_index(drop=True)\n",
    "\n",
    "test_set.to_csv('er_test_set.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''\n",
    "API_URL = 'https://api.perplexity.ai/chat/completions'\n",
    "MODEL   = 'llama-3.1-sonar-large-128k-online'\n",
    "INPUT_CSV  = 'er_test_set.csv'\n",
    "OUTPUT_CSV = 'er_test_icd9_codes.csv'\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "def diagnose_icd9(notes: str) -> str:\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a board‑certified medical coder. It is crucial that you are providing the right range in IC9 codes.\"\n",
    "            \"Return exactly one ICD‑9 code for these clinical notes. Only include the code and no other words with nothing following or before it.\"\n",
    "        )\n",
    "    }\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": notes\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [system_msg, user_msg],\n",
    "        \"max_tokens\": 10,\n",
    "        \"temperature\": 0.0,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    resp = requests.post(API_URL, json=payload, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    content = resp.json()['choices'][0]['message']['content'].strip()\n",
    "    integer_code = content.split('.')[0]\n",
    "    return integer_code\n",
    "\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    pid   = row['patient_id']\n",
    "    notes = row['all_notes']\n",
    "    try:\n",
    "        code = diagnose_icd9(notes)\n",
    "    except Exception:\n",
    "        code = None\n",
    "    results.append({\"patient_id\": pid, \"icd9_code\": code})\n",
    "\n",
    "out_df = pd.DataFrame(results)\n",
    "out_df.to_csv(OUTPUT_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_df = pd.read_csv(\"er_test_icd9_codes.csv\")\n",
    "ground_truth_df = pd.read_csv(\"new_ground_truth.csv\")\n",
    "\n",
    "def safe_eval(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "ground_truth_df['diagnosis'] = ground_truth_df['diagnosis'].apply(safe_eval)\n",
    "\n",
    "\n",
    "merged_df = pd.merge(er_df, ground_truth_df, on='patient_id', how='left')\n",
    "merged_df['icd9_code'] = merged_df['icd9_code'].astype(str)\n",
    "\n",
    "def is_code_in_same_range(icd9_code, diagnosis_list):\n",
    "    try:\n",
    "        icd9_int = int(float(icd9_code)) \n",
    "        icd9_range = icd9_int // 100\n",
    "        for diag in diagnosis_list:\n",
    "            try:\n",
    "                diag_int = int(float(diag))\n",
    "                if diag_int // 100 == icd9_range:\n",
    "                    return True\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "        return False\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "merged_df['is_match'] = merged_df.apply(\n",
    "    lambda row: is_code_in_same_range(row['icd9_code'], row['diagnosis']) if isinstance(row['diagnosis'], list) else False,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "accuracy = merged_df['is_match'].mean()\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(merged_df[['patient_id', 'icd9_code', 'diagnosis', 'is_match']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
